# SLAM 9-11 总结
---
### Chapter 9 后端优化1
- EKF
  - 这个不必多说，使用Python/C++写过几个控制相关的EKF了，有关感知EKF的形式还需要深入了解
- BA 图优化理论
  - 观测方程：h(x，y) 在我们讨论的问题下就是：三维空间路标点y根据位姿x投影到二维平面得到像素坐标的过程
  - 重投影（图像观测 与 投影得到的点之间的误差）
  - BA 优化的是所有观测帧（之后将选取关键帧）以及观测帧中的所有路标点进行优化
    - 同时优化所有帧的位姿以及点的位置 **于是有一个很长的偏导数向量**
  - 使用高斯牛顿或者LM法对Hessian矩阵近似，Hessian都会存在稀疏性（这个很好理解）
  - 根据稀疏性可以把对应非零块 / 相机位姿 / 空间点 之间组成一个图网络模型
  - 利用稀疏性 分块 --- **舒尔Schur消元** 
    - 这也就是 Marginalize (边缘化) 就是概率论中的概念 求某个变量的边缘分布
  - 边缘化的过程：固定被边缘化的变量（**保持状态估计**），求其他变量，借助求其他变量的结果反求被边缘化的变量
  - 边缘化的过程在概率上看就是：条件概率展开。就是说：**固定**过程，相当于给定条件，P(A|B)中的B，而求解A
  - 而P(A, B) = P(A | B)P(B), P(B)则是边缘概率
    - 相当于，本身我们要对（A, B）进行估计，而现在给定B（求解A的过程与B的取值无关，B未知但确定，不影响A），再求A
  - 对变量边缘化会导致：
    - 对于先求解的变量，矩阵稀疏性很可能会被破坏
    - 未被优化的变量信息会转化为先验的形式
    - 比如说，我们边缘化位姿（相当于我提前确定某个位姿，求解对应位姿下观测得到的路标点）
    - 那么先验信息就是：**在对应位姿下，某个路标点所在位置的分布 P(A | B)**
    - 先验信息的作用：对应路标点的在位姿B的分布已经获得了，则我们可以大致得到一个 “对应路标点的位置”的先验信息
    - P(B)这部分可以舍去
  - **边缘化的概念不太好理解**
    - 比如说：某些路标点太老了，我们不想再用它，要剔除掉。但是这些路标点已经估计了，包含了信息，我们不能简单删除，希望让它们发挥最后的作用后再丢弃
    - 我们需要保持这些路标点的状态估计值（固定），求解其他变量关于这些变量的条件概率，得到一个先验概率
    - 也就是大概得到了：相对于这个路标点，其他路标点的先验位置分布 / 其他相机的先验位姿分布
    - 那么此后我们就不再需要这个路标点了 （已经提取了先验信息）（直接丢弃导致信息损失）（让其 被边缘化了 （语文理解一下））
    - 边缘化是为了**保持H矩阵稀疏性，维持计算水平（关键帧或者路标点不会无限制增多）**
  - 比如：
    - 我们希望边缘化旧的关键帧，连通旧的关键帧路标点一起边缘化：最后利用一次信息
  - 鲁棒核函数谈：
    - 我们的二范数，是平方关系的（或者说误差的平方）
    - 这个函数增长速度较快，若引入外点，在优化误差时由于外点误差大，**程序会想办法优化外点**，导致其他内点的错误优化
    - 使用鲁棒核函数如Huber，可以限制误差增速
    - 所以Ceres或者其他地方可以尝试使用以下鲁棒核
---
### Chapter 10 后端优化2
- H 矩阵表达的就是一种共视关系（有相关矩阵的味道，两帧看到同一点，说明存在一定关联性）
- 我们使用位姿图进行优化（使用路标点对两个关键帧的运动进行估计，作为边，而原先的特征路标点优化则不再进行）
- 关于关键帧边缘化，我们在Chap 9中已经讲了很多了，其中比较重要的是：
  - 由于我们在关键帧处理中，先边缘化关键帧（删除过旧的关键帧），那么其对应的变量（路标点对应块）的稀疏性将会被破坏（**由于舒尔补等操作**）
  - 我们需要一并边缘化对应路标点，才能保持稀疏性（否则方程很难解）
---
### Chapter 11 回环检测
- 词袋模型
  - 基于特征点的，对于图像上的特征点经过层级聚类，赋予不同的信息
  - 回环检测的时候，判断两个关键帧上，不同的词的直方图是否类似（表明粗浅的语义信息能够对上）
- 其中涉及到几个概念：
  - 精准率 Precision（TP/ (TP + FP)) 正确分类的比例
  - 召回率 Recall (TP / (TP + FN)) 在所有应该分类正确的情况下，分类正确的比例（假阴性代表着 是阳性）
  - 相当于概率论中的两类错误：准确率高说明 严格：存伪概率小，可能导致较多**漏判**
  - 召回率高：不容易拒真，可能导致较多的**误判** 可以看出两个概念其实存在矛盾
    - 照单全收，不管对错，也就是FN = 0，那么召回率为1，但准确度很低
    - 一律拒绝，全部判为阴性（十分严格），那么假阳性不可能存在，准确率为1，但是漏判多，很多都是假阴性，召回率低
- 相似度理论：
  - TF，词频，某张图中大量存在的特征很有区分度
  - IFT，逆文档频率，字典中出现越少的字，在文中出现的位置有区分度（频率越小的词越容易被找出包含它的上下文）