# 论文总结
### SVO: Fast Semi-Direct Monocular Visual Odometry & LK 20 years
#### 计算方法
- 最难以理解的地方就在 inverse compositional algorithm 处
  - 这在论文`LK 20 years` 中提到，存在四种方式（模板匹配的图像对齐）
  - 这四种方法实际上都是计算图像与模板之间的光度（intensity）误差
  - 在论文中定义了一个叫`warp`的东西，我们将其称为一个 `变换`或者`映射`
  - 比较对原图的变换以及对模板的变换 两者之间的光度误差
  - 需要优化的是变换中的某些参数，光度误差最小时对应的参数是我们需要的参数
  1. 直接LK 法 被称为forward additive
  2. 而Baker et al. 提出的 反向构造法，为inverse compositional
- LK法：
1. 尝试对原图进行变换I(W(x;p))，p为需要优化的参数
2. 计算与模板间的误差 T(x) - I(W(x;p))
3. 由于我们需要估计的是p的该变量dp, 原来的误差写为`||I(W(x;p+dp)) - T(x)||^2`
   - 原来计算的参数点在`p + dp`，简化计算我们取p处的一阶Taylor展开
   - 得到`||I(W(x;p)) + grad(I)(dW/dp)dp - T(x)||^2` <<< 这就是我们需要minimize的一项
   - 其中grad(I)是I在W(x;p)处的梯度（链式求导嘛）
   - 既然要最小化，那么就要求导，使用相应的迭代法求解dp的值，对dp求偏导数
   - 可以根据求导等于0的值求出相应的（Hessian矩阵近似解）
   - 我们的dW/dp也需要在参数p位置求出，grad(I)也是在p处求出的
   - 这产生了一个问题，每迭代一次p，p要更新 p = p + dp, 都要重新求grad(I) 与dW/dp，cost是比较大的
4. 得到SD（最速下降算子处理的）图像grad(I)*dW/dp
5. 使用近似法计算Hessian矩阵 可以知道，H矩阵也是每迭代一次就要求一次的
6. 更新dp 求出最小化光度误差的p
- 构造（compositional）法：
  - 相比于更新参数，构造法直接更新的是warp的计算结果
  - 合成法每次更新 W(x;p) `W(x;p) = W(x;p) @ W(x:dp)` 其中`@`是某种合成公式
  - 每次我们计算W(x;dp), 这样在求导操作dW/dp时，由于p不更新，dW/dp不需要再计算了
  - 同样是一阶泰勒展开，我们可以得到与LK法极其类似的结果，由于我们在W(x;0)对合成法的误差式进行展开，在dW/dp的值也是对应的p = 0处的值
- 反向构造法
  - 正向时，我们计算：原图在如何改变(W(x;p))才能使光度误差最小？而反向时，我们讨论，模板图在何种变换W(x;p)的情况下能最小化光度误差`summa(||T(W(x;dp))) - I(W(x;p))||^2`
  - 原图进行W(x;p)的变换，但是变换参数没有优化，正向时我们需要优化成一个W(x;p + dp)的形式
  - 而反向时，我们需要计算的则是模板进行变换 T(W(x;dp)) 与变换后的原图 I(W(x;p))的光度误差
  - 此后可以根据模板的变换W(x;dp)对原图的变换进行优化
  > W(x; p) ← W(x; p) ◦ W(x; p)^−1
  - 对于误差函数式，进行模板W(x;0)处的Taylor一阶展开得到
  > summa x [T (W(x; 0)) + ∇T ∂W/∂p Δp − I(W(x; p))]^2.
  - 其中∇T是模板的梯度，而我们知道，输入的需要匹配的图像可能有很多，每次都不一样，每次执行时都需要求梯度，而模板则不一样，模板给定，那么就可以在初始化阶段就预先计算模板的梯度
  - 通过叠加法（additive）到合成（compositional）到反向合成(inverse compositional)我们让计算变得简单了很多（优化的内容是完全等价的）**追求尽可能多的pre-computation以及data reuse**
- 解释完了inverse compositional algo 我们可以看一下SVO的具体步骤
  - SVO 单目视觉，对时间上连续的帧进行匹配以估计深度，保存关键帧以后进行优化
  1. 新的图像与之前的图像进行对齐（光度误差最小化以及稀疏特征匹配）
  2. 最小化光度误差
    - 使用对极约束（新的帧的每一个像素，在之前帧对应极线上寻找与之匹配的点）
    - 能找到大部分像素的匹配像素点，之后对所有像素整体进行优化 argmin(camera translation and rotation)
    - 此时得到了一个相机位姿变换的估计
    - 对一个n * n 的小patch进行光度误差优化（不是对每一个像素，论文使用4 * 4）
    - 不多说，计算部分使用了Inverse Compositional Algorithm 来对前后帧的匹配（前帧相当于模板，后帧相当于待匹配图片）进行加速
  3. 在Map中，结合关键帧，对图像上的Fast特征进行配对（这个将可能违反对极约束，毕竟可能匹配的特征对不在极线上）
    - 可以强行理解为一种先验上的对齐 (像素光度误差对齐只是对没有过多物理意义的像素点进行匹配，而特征则含有一定的先验信息) 
    - 与地图信息进行结合优化，光度误差容易积累，需要已经有的并且优化后的地图对配准误差进行消除
  - **以上几步还是在优化：2D-2D误差最小化**
  4. 对重投影误差进行优化：我们已经有
     - 在之前的帧中，我们存在有像素点的深度信息以及某个像素或者patch与某个3D点的对应关系
     - 并且可以通过三角计算 + 相机运动的估计来获得对两个匹配点对应的深度估计值
     - 那么我们实际上可以通过反投影方程（比如说相机模型逆用）来求空间点的位置
     - 在之前的步骤中实际上已经求出了3D-2D点对的对应关系，根据这个关系来进行重投影
     - 位姿如何改变才能使3D点投影到2D平面上的误差尽可能小？
     - **还不太清楚的地方**
     - [ ] motion-only BA 优化相机的位姿
     - [ ] structure-only BA 优化3D点坐标
  5. 建图过程 
- 建图过程
  - 与之相关的是3D点插入，关键帧以及地图维护，2D点深度估计
  - 2D点深度估计使用的是概率滤波的方式，不仅维护一个深度值，还维护一个不确定度，光靠两帧对深度进行计算（三角计算）是可能有较大误差的，多帧概率滤波的方式，滤波迭代至不确定度小于一定值时，认为维护的深度值收敛到期望位置。
  - 深度滤波器的形式比较复杂，需要静下心来看（如何进行深度估计的），具体的数学推导暂且先略去，我们着重思路的理解
    - 关键帧：插入种子点（提取关键帧上的特征），在这里我们简要地介绍一下[关键帧（keyFrame）](#keyframe)
    - 普通帧中: 对于关键帧中找到的特征点，我们需要匹配这些特征点，并且利用普通帧信息去更新概率分布
    - 假设某个点的深度收敛，那么这个点会被加入到地图点中，之后进行追踪或者优化
#### 思路简述
1. 前后帧patches光度配准优化 （直接，稠密）
2. 前后帧特征点优化          （特征，稀疏）
3. 结合地图信息的BA 位姿或者空间点优化  （全局优化）
4. 同时进行地图构建
5. 像素点或patch深度分布维护更新，选择添加或删除点（>>> 与 3 有关）

#### TODO：
- [ ] 深度概率滤波器
- [ ] 各种BA方法

#### 概念解释
<span id="keyframe">
- 关键帧
  - 关键帧：可以代表其附近的普通帧，比如说，一个视频中相机就不怎么动，那么它拍到的图像有大部分是基本相同的(冗余)
  - 那么我们可以通过一帧来代表周围这些帧，计算时就可以只使用这一帧
  - 比如进行SfM操作，三角估计深度，使用重复的帧进行计算显然是没有意义的，只需要两个关键帧，关键帧之间必然存在很大的差异（否则基本相同的话，那两个相似的关键帧没有意义），通过这两个关键帧进行计算
</span>